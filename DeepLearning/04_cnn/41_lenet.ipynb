{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4be0ee127ad1ca7cbe5adc273b343977",
     "grade": false,
     "grade_id": "cell-440df6cfa709812f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Number of points for this notebook:</b> 1\n",
    "<br>\n",
    "<b>Deadline:</b> March 23, 2020 (Monday). 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 4.1. Convolutional neural networks. LeNet-5.\n",
    "\n",
    "In this exercise, you will train a very simple convolutional neural network used for image classification tasks.\n",
    "\n",
    "If you are not fluent with PyTorch, you may find it useful to look at this tutorial:\n",
    "* [Neural Networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "# data_dir = tools.select_data_dir('/Users/jiayizhang/Documents/Aalto/deep_learning/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d33ffe246f5459117f53cac15b370d",
     "grade": false,
     "grade_id": "cell-fe95dcf02c6b9c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "889ef743f5d3f1f0499804525691113a",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c73c2020ffaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3eec87e2b4206e1a149c9169348fcc3",
     "grade": false,
     "grade_id": "cell-a8894f680446eafa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let us visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bfb149491d7094038a73acd50f94687",
     "grade": false,
     "grade_id": "cell-b830430a1313650a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b937a054a2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "images, labels = iter(trainloader).next()\n",
    "tests.plot_images(images[:8], n_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6c23d31cbad1c0d5eb1dc397e69202a",
     "grade": false,
     "grade_id": "cell-84bcd5c448fd8cd4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# 1. Simple convolutional network\n",
    "\n",
    "In the first exercise, your task is to create a convolutional neural network with the architecture inspired by the classical LeNet-5 [(LeCun et al., 1998)](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf):\n",
    "\n",
    "<img src=\"simple_net.png\" width=350 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cd64ce44349d874f0945452240cd0d5",
     "grade": false,
     "grade_id": "cell-8b44b42206140b1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The architecture of the convolutional network that you need to create:\n",
    "* 2d convolutional layer with:\n",
    "    * one input channel\n",
    "    * 16 output channels\n",
    "    * kernel size 5 (no padding)\n",
    "    * followed by ReLU\n",
    "* Max-pooling layer with kernel size 2 and stride 2\n",
    "* 2d convolutional layer with:\n",
    "    * 32 output channels\n",
    "    * kernel size 5 (no padding)\n",
    "    * followed by ReLU\n",
    "* Max-pooling layer with kernel size 2 and stride 2\n",
    "* A fully-connected layer with:\n",
    "    * 120 outputs\n",
    "    * followed by ReLU\n",
    "* A fully-connected layer with:\n",
    "    * 84 outputs\n",
    "    * followed by ReLU\n",
    "* A fully-connected layer with 10 outputs and without nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4abe6ec43a7c984c4012b918ef95c1bf",
     "grade": false,
     "grade_id": "LeNet5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # YOUR CODE HERE\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # raise NotImplementedError()\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        print(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        print(x.size())\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "397fc66524db07f162f4a5be7a49f027",
     "grade": false,
     "grade_id": "cell-95587f8277f8ff68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 32, 4, 4])\n",
      "torch.Size([32, 512])\n",
      "torch.Size([32, 84])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_LeNet5_shapes():\n",
    "    net = LeNet5()\n",
    "\n",
    "    # Feed a batch of images from the training data to test the network\n",
    "    with torch.no_grad():\n",
    "        images, labels = iter(trainloader).next()\n",
    "        print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "        y = net(images)\n",
    "        assert y.shape == torch.Size([trainloader.batch_size, 10]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_LeNet5_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "107026b7f80bce8657e00c43ee4c7dfa",
     "grade": true,
     "grade_id": "test_LeNet5",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000]], grad_fn=<AddmmBackward>)\n",
      "expected: tensor([ 1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "tests.test_LeNet5(LeNet5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "824d2a50422e0f38599122287116a30d",
     "grade": false,
     "grade_id": "cell-c577fd827241ab3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b87c28d8f82a2bce0f854fbb38a2499b",
     "grade": false,
     "grade_id": "cell-b4de7f71752f38fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5299b3762f7521227ad010472a8a9e7a",
     "grade": false,
     "grade_id": "cell-6ade8368217a66dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Your task is to implement the training loop. The recommended hyperparameters:\n",
    "* Stochastic Gradient Descent (SCG) optimizer with learning rate 0.001 and momentum 0.9.\n",
    "* Cross-entropy loss. Note that we did not use softmax nonlinearity in the final layer of our network. Therefore, we need to use a loss function with log_softmax implemented, such as [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss).\n",
    "* Number of epochs: 10\n",
    "\n",
    "We recommend you to use function `compute_accuracy()` defined above to track the accuracy during training. The test accuracy should be above 0.87."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2ced3685882aaa9f96e2ac161ed22f8",
     "grade": false,
     "grade_id": "cell-68ccc4068c5cae0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create network\n",
    "net = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6270848f5387bf01aba9bb5f50303a78",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757\n",
      "0.8062\n",
      "0.8266\n",
      "0.8492\n",
      "0.8586\n",
      "0.8631\n",
      "0.867\n",
      "0.876\n",
      "0.8849\n",
      "0.8851\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    epochs=10\n",
    "    \n",
    "    \n",
    "    opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    los = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in trainloader:\n",
    "            \n",
    "            pred = net(xb)\n",
    "            \n",
    "            loss = los(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            #loss.backward() updates the gradients of the model, \n",
    "            #in this case, weights and bias.\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        print(compute_accuracy(net, testloader))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c0de1830afda74c01d3b5083ffdce15",
     "grade": false,
     "grade_id": "cell-6e2ddf6eac7edc18",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 4_lenet5.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    tools.save_model(net, '4_lenet5.pth')\n",
    "else:\n",
    "    net = LeNet5()\n",
    "    tools.load_model(net, '4_lenet5.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e8c0a8c4072d46942d62fe3b05229cb",
     "grade": false,
     "grade_id": "cell-d786a74f883ad32e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth labels:  Ankle boot   Pullover    Trouser    Trouser      Shirt\n",
      "Predictions:          Ankle boot   Pullover    Trouser    Trouser      Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display random images from the test set, the ground truth labels and the network's predictions\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels = iter(testloader).next()\n",
    "    tests.plot_images(images[:5], n_rows=1)\n",
    "    \n",
    "    # Compute predictions\n",
    "    images = images.to(device)\n",
    "    y = net(images)\n",
    "\n",
    "print('Ground truth labels: ', ' '.join('%10s' % classes[labels[j]] for j in range(5)))\n",
    "print('Predictions:         ', ' '.join('%10s' % classes[j] for j in y.argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebd3250ccf1b7701b1eb9eead9ab8517",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 0.885\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print('Accuracy of the network on the test images: %.3f' % accuracy)\n",
    "assert accuracy > 0.87, \"Poor accuracy {:.3f}\".format(accuracy)\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
